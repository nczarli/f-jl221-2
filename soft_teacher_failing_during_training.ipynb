{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQ9y6uogPD3oC7fxU4upy8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nczarli/f-jl221-2/blob/main/soft_teacher_failing_during_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQRsDa3Adg6n",
        "outputId": "ac5fc6a9-d6fb-42f6-965a-a7c1a264ab3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'f-jl221-2'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 106 (delta 42), reused 67 (delta 21), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (106/106), 4.13 MiB | 4.76 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n",
            "Cloning into 'SoftTeacherCustomDataset'...\n",
            "remote: Enumerating objects: 306, done.\u001b[K\n",
            "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 306 (delta 116), reused 106 (delta 101), pack-reused 148\u001b[K\n",
            "Receiving objects: 100% (306/306), 590.22 KiB | 9.08 MiB/s, done.\n",
            "Resolving deltas: 100% (144/144), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nczarli/f-jl221-2.git\n",
        "!git clone https://github.com/nczarli/SoftTeacherCustomDataset.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLo416fmhx32",
        "outputId": "8c51981f-4b31-49ee-d1b5-a6c2b3e48255"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mf-jl221-2\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34mSoftTeacherCustomDataset\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd SoftTeacherCustomDataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeAv9-TUhzHS",
        "outputId": "3a33dae5-d54c-418b-ce3e-2eb72c34f3dd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SoftTeacherCustomDataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZgJDJOXkIqI",
        "outputId": "da1e40b5-8a25-49b1-9398-65cc759d2dcb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mconfigs\u001b[0m/  LICENSE   README.md         \u001b[01;34mresources\u001b[0m/   setup.py  \u001b[01;34mtools\u001b[0m/\n",
            "\u001b[01;34mdemo\u001b[0m/     Makefile  requirements.txt  SECURITY.md  \u001b[01;34mssod\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcRWylwLnAmV",
        "outputId": "a8782eb0-ca51-4581-e435-d1d07a094dab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
            "\u001b[K     |█████████████                   | 834.1 MB 1.3 MB/s eta 0:14:59tcmalloc: large alloc 1147494400 bytes == 0x39a44000 @  0x7f1443789615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 1.3 MB/s eta 0:13:08tcmalloc: large alloc 1434370048 bytes == 0x7e09a000 @  0x7f1443789615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 1.3 MB/s eta 0:09:11tcmalloc: large alloc 1792966656 bytes == 0x2ecc000 @  0x7f1443789615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.2 MB/s eta 0:04:52tcmalloc: large alloc 2241208320 bytes == 0x6dcb4000 @  0x7f1443789615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf3616000 @  0x7f14437881e7 0x4b2590 0x4b261c 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6\n",
            "tcmalloc: large alloc 2551685120 bytes == 0x1e159a000 @  0x7f1443789615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x4bad99 0x4d3249\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 7.2 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 31.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mmcv-full==1.3.17 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4S8g2uJoiSy",
        "outputId": "07ba05cc-7864-4c5e-accf-233827273cc8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
            "Collecting mmcv-full==1.3.17\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/mmcv_full-1.3.17-cp37-cp37m-manylinux1_x86_64.whl (50.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 50.4 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.17) (0.32.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.17) (6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.17) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.17) (1.21.6)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.17) (2.4.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.17) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.17) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full==1.3.17) (3.0.9)\n",
            "Installing collected packages: mmcv-full\n",
            "  Attempting uninstall: mmcv-full\n",
            "    Found existing installation: mmcv-full 1.3.0\n",
            "    Uninstalling mmcv-full-1.3.0:\n",
            "      Successfully uninstalled mmcv-full-1.3.0\n",
            "Successfully installed mmcv-full-1.3.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56s992D7kSFe",
        "outputId": "5ecb6226-6c6a-4029-9891-2913eedb7b9d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make pre\n",
            "make[1]: Entering directory '/content/SoftTeacherCustomDataset'\n",
            "python -m pip install -r requirements.txt -f https://download.pytorch.org/whl/torch_stable.html\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.10.0+cu111)\n",
            "Requirement already satisfied: mmcv-full in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.3.0)\n",
            "Collecting wandb\n",
            "  Using cached wandb-0.13.5-py2.py3-none-any.whl (1.9 MB)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full->-r requirements.txt (line 3)) (6.0)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmcv-full->-r requirements.txt (line 3)) (2.4.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmcv-full->-r requirements.txt (line 3)) (0.32.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 4)) (2.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 4)) (5.4.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 4)) (1.15.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 4)) (3.17.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Using cached GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "Collecting setproctitle\n",
            "  Using cached setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting pathtools\n",
            "  Using cached pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Using cached shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 4)) (57.4.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Using cached sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 4)) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 4)) (1.24.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Using cached sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
            "  Using cached sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "  Using cached sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "  Using cached sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "  Using cached sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "  Using cached sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "  Using cached sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "  Using cached sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "  Using cached sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "  Using cached sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "  Using cached sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "  Using cached sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->-r requirements.txt (line 5)) (4.13.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->-r requirements.txt (line 5)) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->-r requirements.txt (line 5)) (3.10.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=4f104c39c0a5cd674a666cec59ddd7be3a33bb2314c1b8c1de282cb6e49425e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.5\n",
            "mkdir -p thirdparty\n",
            "git clone https://github.com/open-mmlab/mmdetection.git thirdparty/mmdetection\n",
            "Cloning into 'thirdparty/mmdetection'...\n",
            "remote: Enumerating objects: 32353, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 32353 (delta 5), reused 5 (delta 3), pack-reused 32338\u001b[K\n",
            "Receiving objects: 100% (32353/32353), 41.84 MiB | 33.63 MiB/s, done.\n",
            "Resolving deltas: 100% (23301/23301), done.\n",
            "cd thirdparty/mmdetection && python -m pip install -e .\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/SoftTeacherCustomDataset/thirdparty/mmdetection\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet==2.25.3) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet==2.25.3) (1.21.6)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet==2.25.3) (2.0.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet==2.25.3) (1.15.0)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.25.3) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.25.3) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.25.3) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.25.3) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmdet==2.25.3) (4.1.1)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet-2.25.3 terminaltables-3.1.10\n",
            "make[1]: Leaving directory '/content/SoftTeacherCustomDataset'\n",
            "python -m pip install -e .\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/SoftTeacherCustomDataset\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ssod==0.0.1) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from ssod==0.0.1) (0.10.0+cu111)\n",
            "Requirement already satisfied: mmcv-full in /usr/local/lib/python3.7/dist-packages (from ssod==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (from ssod==0.0.1) (0.13.5)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from ssod==0.0.1) (3.4.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmcv-full->ssod==0.0.1) (0.32.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full->ssod==0.0.1) (6.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full->ssod==0.0.1) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full->ssod==0.0.1) (1.21.6)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmcv-full->ssod==0.0.1) (2.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->ssod==0.0.1) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->ssod==0.0.1) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->ssod==0.0.1) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->ssod==0.0.1) (3.10.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->ssod==0.0.1) (2.3)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->ssod==0.0.1) (3.17.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb->ssod==0.0.1) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb->ssod==0.0.1) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb->ssod==0.0.1) (57.4.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->ssod==0.0.1) (1.9.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb->ssod==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->ssod==0.0.1) (3.1.29)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb->ssod==0.0.1) (0.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->ssod==0.0.1) (2.23.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->ssod==0.0.1) (5.4.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->ssod==0.0.1) (7.1.2)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb->ssod==0.0.1) (1.0.9)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb->ssod==0.0.1) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->ssod==0.0.1) (5.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->ssod==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->ssod==0.0.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->ssod==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->ssod==0.0.1) (2022.9.24)\n",
            "Installing collected packages: ssod\n",
            "  Running setup.py develop for ssod\n",
            "Successfully installed ssod-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2LrltuRkiCe",
        "outputId": "d2797360-2fc4-46a0-eb39-a276ee62295f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ2slsHPlPDJ",
        "outputId": "cb5bc18b-8ee2-4cfc-fabe-2f2e8fae1f7c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mf-jl221-2\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34mSoftTeacherCustomDataset\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -R f-jl221-2/labels_generated/ SoftTeacherCustomDataset/labels_generated"
      ],
      "metadata": {
        "id": "Q1sLAxofsoAi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd SoftTeacherCustomDataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfpKzmZSsx3k",
        "outputId": "42f0a963-ecae-41a5-acf3-e28700a139cc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'SoftTeacherCustomDataset/'\n",
            "/content/SoftTeacherCustomDataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a57qK_Ls0YO",
        "outputId": "e79fb3c9-6ab7-4e7c-ca16-a87c767899bd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mconfigs\u001b[0m/           LICENSE    requirements.txt  setup.py        \u001b[01;34mthirdparty\u001b[0m/\n",
            "\u001b[01;34mdemo\u001b[0m/              Makefile   \u001b[01;34mresources\u001b[0m/        \u001b[01;34mssod\u001b[0m/           \u001b[01;34mtools\u001b[0m/\n",
            "\u001b[01;34mlabels_generated\u001b[0m/  README.md  SECURITY.md       \u001b[01;34mssod.egg-info\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash tools/dist_train.sh configs/baseline/faster_rcnn_r101_caffe_fpn_generated_label.py 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l3MTQ_Ts04O",
        "outputId": "00ae5771-7f8b-4721-9535-9ef0bdc856e8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:164: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
            "  \"The module torch.distributed.launch is deprecated \"\n",
            "The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run\n",
            "WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.\n",
            " Please read local_rank from `os.environ('LOCAL_RANK')` instead.\n",
            "INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:\n",
            "  entrypoint       : tools/train.py\n",
            "  min_nodes        : 1\n",
            "  max_nodes        : 1\n",
            "  nproc_per_node   : 1\n",
            "  run_id           : none\n",
            "  rdzv_backend     : static\n",
            "  rdzv_endpoint    : 127.0.0.1:29500\n",
            "  rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
            "  max_restarts     : 3\n",
            "  monitor_interval : 5\n",
            "  log_dir          : None\n",
            "  metrics_cfg      : {}\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_asxy3k7z/none_qq0s7vn7\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\n",
            "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
            "  restart_count=0\n",
            "  master_addr=127.0.0.1\n",
            "  master_port=29500\n",
            "  group_rank=0\n",
            "  group_world_size=1\n",
            "  local_ranks=[0]\n",
            "  role_ranks=[0]\n",
            "  global_ranks=[0]\n",
            "  role_world_sizes=[1]\n",
            "  global_world_sizes=[1]\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_asxy3k7z/none_qq0s7vn7/attempt_0/0/error.json\n",
            "/content/SoftTeacherCustomDataset/thirdparty/mmdetection/mmdet/datasets/pipelines/formating.py:7: UserWarning: DeprecationWarning: mmdet.datasets.pipelines.formating will be deprecated, please replace it with mmdet.datasets.pipelines.formatting.\n",
            "  warnings.warn('DeprecationWarning: mmdet.datasets.pipelines.formating will be '\n",
            "2022-11-07 02:00:13,763 - mmdet.ssod - INFO - [<StreamHandler <stderr> (INFO)>, <FileHandler /content/SoftTeacherCustomDataset/work_dirs/faster_rcnn_r101_caffe_fpn_generated_label/20221107_020013.log (INFO)>]\n",
            "2022-11-07 02:00:13,763 - mmdet.ssod - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.15 (default, Oct 12 2022, 19:14:55) [GCC 7.5.0]\n",
            "CUDA available: True\n",
            "GPU 0: Tesla T4\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Build cuda_11.2.r11.2/compiler.29618528_0\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.9.0+cu111\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.0.5\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "TorchVision: 0.10.0+cu111\n",
            "OpenCV: 4.6.0\n",
            "MMCV: 1.3.17\n",
            "MMCV Compiler: GCC 7.3\n",
            "MMCV CUDA Compiler: 11.1\n",
            "MMDetection: 2.25.3+fc09f2a\n",
            "------------------------------------------------------------\n",
            "\n",
            "2022-11-07 02:00:14,140 - mmdet.ssod - INFO - Distributed training: True\n",
            "2022-11-07 02:00:14,531 - mmdet.ssod - INFO - Config:\n",
            "model = dict(\n",
            "    type='FasterRCNN',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=101,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=False),\n",
            "        norm_eval=True,\n",
            "        style='caffe',\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained',\n",
            "            checkpoint='open-mmlab://detectron2/resnet50_caffe')),\n",
            "    neck=dict(\n",
            "        type='FPN',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='StandardRoIHead',\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        bbox_head=[\n",
            "            dict(type='Shared2FCBBoxHead', num_classes=3),\n",
            "            dict(type='Shared2FCBBoxHead', num_classes=3),\n",
            "            dict(type='Shared2FCBBoxHead', num_classes=3)\n",
            "        ]),\n",
            "    train_cfg=dict(\n",
            "        rpn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.3,\n",
            "                min_pos_iou=0.3,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=False),\n",
            "            allowed_border=-1,\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        rpn_proposal=dict(\n",
            "            nms_pre=2000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)),\n",
            "    test_cfg=dict(\n",
            "        rpn=dict(\n",
            "            nms_pre=1000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            score_thr=0.05,\n",
            "            nms=dict(type='nms', iou_threshold=0.5),\n",
            "            max_per_img=100)))\n",
            "dataset_type = 'CocoDataset'\n",
            "data_root = 'data/coco/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        type='Sequential',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='RandResize',\n",
            "                img_scale=[(1333, 400), (1333, 1200)],\n",
            "                multiscale_mode='range',\n",
            "                keep_ratio=True),\n",
            "            dict(type='RandFlip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(type='Identity'),\n",
            "                    dict(type='AutoContrast'),\n",
            "                    dict(type='RandEqualize'),\n",
            "                    dict(type='RandSolarize'),\n",
            "                    dict(type='RandColor'),\n",
            "                    dict(type='RandContrast'),\n",
            "                    dict(type='RandBrightness'),\n",
            "                    dict(type='RandSharpness'),\n",
            "                    dict(type='RandPosterize')\n",
            "                ])\n",
            "        ]),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[103.53, 116.28, 123.675],\n",
            "        std=[1.0, 1.0, 1.0],\n",
            "        to_rgb=False),\n",
            "    dict(type='ExtraAttrs', tag='sup'),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(\n",
            "        type='Collect',\n",
            "        keys=['img', 'gt_bboxes', 'gt_labels'],\n",
            "        meta_keys=('filename', 'ori_shape', 'img_shape', 'img_norm_cfg',\n",
            "                   'pad_shape', 'scale_factor', 'tag'))\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(1333, 800),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[103.53, 116.28, 123.675],\n",
            "                std=[1.0, 1.0, 1.0],\n",
            "                to_rgb=False),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=1,\n",
            "    workers_per_gpu=1,\n",
            "    train=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='./labels_generated/train/annotations/instances_default.json',\n",
            "        img_prefix='./labels_generated/train/images/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                type='Sequential',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='RandResize',\n",
            "                        img_scale=[(1333, 400), (1333, 1200)],\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandFlip', flip_ratio=0.5),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(type='Identity'),\n",
            "                            dict(type='AutoContrast'),\n",
            "                            dict(type='RandEqualize'),\n",
            "                            dict(type='RandSolarize'),\n",
            "                            dict(type='RandColor'),\n",
            "                            dict(type='RandContrast'),\n",
            "                            dict(type='RandBrightness'),\n",
            "                            dict(type='RandSharpness'),\n",
            "                            dict(type='RandPosterize')\n",
            "                        ])\n",
            "                ]),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[103.53, 116.28, 123.675],\n",
            "                std=[1.0, 1.0, 1.0],\n",
            "                to_rgb=False),\n",
            "            dict(type='ExtraAttrs', tag='sup'),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels'],\n",
            "                meta_keys=('filename', 'ori_shape', 'img_shape',\n",
            "                           'img_norm_cfg', 'pad_shape', 'scale_factor', 'tag'))\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='./labels_generated/test/annotations/instances_default.json',\n",
            "        img_prefix='./labels_generated/train/images/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1333, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[103.53, 116.28, 123.675],\n",
            "                        std=[1.0, 1.0, 1.0],\n",
            "                        to_rgb=False),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='./labels_generated/test/annotations/instances_default.json',\n",
            "        img_prefix='./labels_generated/train/images/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1333, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[103.53, 116.28, 123.675],\n",
            "                        std=[1.0, 1.0, 1.0],\n",
            "                        to_rgb=False),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=4000, metric='bbox')\n",
            "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.001,\n",
            "    step=[480000, 640000])\n",
            "runner = dict(type='IterBasedRunner', max_iters=720000)\n",
            "checkpoint_config = dict(interval=4000, by_epoch=False, max_keep_ckpts=10)\n",
            "log_config = dict(\n",
            "    interval=50,\n",
            "    hooks=[\n",
            "        dict(type='TextLoggerHook', by_epoch=False),\n",
            "        dict(\n",
            "            type='WandbLoggerHook',\n",
            "            init_kwargs=dict(\n",
            "                project='pre_release',\n",
            "                name='faster_rcnn_r101_caffe_fpn_generated_label',\n",
            "                config=dict(\n",
            "                    work_dirs=\n",
            "                    './work_dirs/faster_rcnn_r101_caffe_fpn_generated_label',\n",
            "                    total_step=720000)),\n",
            "            by_epoch=False)\n",
            "    ])\n",
            "custom_hooks = [dict(type='NumClassCheckHook')]\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
            "mmdet_base = '../../thirdparty/mmdetection/configs/_base_'\n",
            "fp16 = dict(loss_scale='dynamic')\n",
            "dataset_root = './labels_generated/train/'\n",
            "classes = ('pitted', 'not_pitted', 'try_again')\n",
            "work_dir = './work_dirs/faster_rcnn_r101_caffe_fpn_generated_label'\n",
            "cfg_name = 'faster_rcnn_r101_caffe_fpn_generated_label'\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "2022-11-07 02:00:15,304 - mmdet.ssod - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'open-mmlab://detectron2/resnet50_caffe'}\n",
            "2022-11-07 02:00:15,305 - mmcv - INFO - load model from: open-mmlab://detectron2/resnet50_caffe\n",
            "2022-11-07 02:00:15,305 - mmcv - INFO - load checkpoint from openmmlab path: open-mmlab://detectron2/resnet50_caffe\n",
            "2022-11-07 02:00:15,401 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: conv1.bias\n",
            "\n",
            "missing keys in source state_dict: layer3.6.conv1.weight, layer3.6.bn1.weight, layer3.6.bn1.bias, layer3.6.bn1.running_mean, layer3.6.bn1.running_var, layer3.6.conv2.weight, layer3.6.bn2.weight, layer3.6.bn2.bias, layer3.6.bn2.running_mean, layer3.6.bn2.running_var, layer3.6.conv3.weight, layer3.6.bn3.weight, layer3.6.bn3.bias, layer3.6.bn3.running_mean, layer3.6.bn3.running_var, layer3.7.conv1.weight, layer3.7.bn1.weight, layer3.7.bn1.bias, layer3.7.bn1.running_mean, layer3.7.bn1.running_var, layer3.7.conv2.weight, layer3.7.bn2.weight, layer3.7.bn2.bias, layer3.7.bn2.running_mean, layer3.7.bn2.running_var, layer3.7.conv3.weight, layer3.7.bn3.weight, layer3.7.bn3.bias, layer3.7.bn3.running_mean, layer3.7.bn3.running_var, layer3.8.conv1.weight, layer3.8.bn1.weight, layer3.8.bn1.bias, layer3.8.bn1.running_mean, layer3.8.bn1.running_var, layer3.8.conv2.weight, layer3.8.bn2.weight, layer3.8.bn2.bias, layer3.8.bn2.running_mean, layer3.8.bn2.running_var, layer3.8.conv3.weight, layer3.8.bn3.weight, layer3.8.bn3.bias, layer3.8.bn3.running_mean, layer3.8.bn3.running_var, layer3.9.conv1.weight, layer3.9.bn1.weight, layer3.9.bn1.bias, layer3.9.bn1.running_mean, layer3.9.bn1.running_var, layer3.9.conv2.weight, layer3.9.bn2.weight, layer3.9.bn2.bias, layer3.9.bn2.running_mean, layer3.9.bn2.running_var, layer3.9.conv3.weight, layer3.9.bn3.weight, layer3.9.bn3.bias, layer3.9.bn3.running_mean, layer3.9.bn3.running_var, layer3.10.conv1.weight, layer3.10.bn1.weight, layer3.10.bn1.bias, layer3.10.bn1.running_mean, layer3.10.bn1.running_var, layer3.10.conv2.weight, layer3.10.bn2.weight, layer3.10.bn2.bias, layer3.10.bn2.running_mean, layer3.10.bn2.running_var, layer3.10.conv3.weight, layer3.10.bn3.weight, layer3.10.bn3.bias, layer3.10.bn3.running_mean, layer3.10.bn3.running_var, layer3.11.conv1.weight, layer3.11.bn1.weight, layer3.11.bn1.bias, layer3.11.bn1.running_mean, layer3.11.bn1.running_var, layer3.11.conv2.weight, layer3.11.bn2.weight, layer3.11.bn2.bias, layer3.11.bn2.running_mean, layer3.11.bn2.running_var, layer3.11.conv3.weight, layer3.11.bn3.weight, layer3.11.bn3.bias, layer3.11.bn3.running_mean, layer3.11.bn3.running_var, layer3.12.conv1.weight, layer3.12.bn1.weight, layer3.12.bn1.bias, layer3.12.bn1.running_mean, layer3.12.bn1.running_var, layer3.12.conv2.weight, layer3.12.bn2.weight, layer3.12.bn2.bias, layer3.12.bn2.running_mean, layer3.12.bn2.running_var, layer3.12.conv3.weight, layer3.12.bn3.weight, layer3.12.bn3.bias, layer3.12.bn3.running_mean, layer3.12.bn3.running_var, layer3.13.conv1.weight, layer3.13.bn1.weight, layer3.13.bn1.bias, layer3.13.bn1.running_mean, layer3.13.bn1.running_var, layer3.13.conv2.weight, layer3.13.bn2.weight, layer3.13.bn2.bias, layer3.13.bn2.running_mean, layer3.13.bn2.running_var, layer3.13.conv3.weight, layer3.13.bn3.weight, layer3.13.bn3.bias, layer3.13.bn3.running_mean, layer3.13.bn3.running_var, layer3.14.conv1.weight, layer3.14.bn1.weight, layer3.14.bn1.bias, layer3.14.bn1.running_mean, layer3.14.bn1.running_var, layer3.14.conv2.weight, layer3.14.bn2.weight, layer3.14.bn2.bias, layer3.14.bn2.running_mean, layer3.14.bn2.running_var, layer3.14.conv3.weight, layer3.14.bn3.weight, layer3.14.bn3.bias, layer3.14.bn3.running_mean, layer3.14.bn3.running_var, layer3.15.conv1.weight, layer3.15.bn1.weight, layer3.15.bn1.bias, layer3.15.bn1.running_mean, layer3.15.bn1.running_var, layer3.15.conv2.weight, layer3.15.bn2.weight, layer3.15.bn2.bias, layer3.15.bn2.running_mean, layer3.15.bn2.running_var, layer3.15.conv3.weight, layer3.15.bn3.weight, layer3.15.bn3.bias, layer3.15.bn3.running_mean, layer3.15.bn3.running_var, layer3.16.conv1.weight, layer3.16.bn1.weight, layer3.16.bn1.bias, layer3.16.bn1.running_mean, layer3.16.bn1.running_var, layer3.16.conv2.weight, layer3.16.bn2.weight, layer3.16.bn2.bias, layer3.16.bn2.running_mean, layer3.16.bn2.running_var, layer3.16.conv3.weight, layer3.16.bn3.weight, layer3.16.bn3.bias, layer3.16.bn3.running_mean, layer3.16.bn3.running_var, layer3.17.conv1.weight, layer3.17.bn1.weight, layer3.17.bn1.bias, layer3.17.bn1.running_mean, layer3.17.bn1.running_var, layer3.17.conv2.weight, layer3.17.bn2.weight, layer3.17.bn2.bias, layer3.17.bn2.running_mean, layer3.17.bn2.running_var, layer3.17.conv3.weight, layer3.17.bn3.weight, layer3.17.bn3.bias, layer3.17.bn3.running_mean, layer3.17.bn3.running_var, layer3.18.conv1.weight, layer3.18.bn1.weight, layer3.18.bn1.bias, layer3.18.bn1.running_mean, layer3.18.bn1.running_var, layer3.18.conv2.weight, layer3.18.bn2.weight, layer3.18.bn2.bias, layer3.18.bn2.running_mean, layer3.18.bn2.running_var, layer3.18.conv3.weight, layer3.18.bn3.weight, layer3.18.bn3.bias, layer3.18.bn3.running_mean, layer3.18.bn3.running_var, layer3.19.conv1.weight, layer3.19.bn1.weight, layer3.19.bn1.bias, layer3.19.bn1.running_mean, layer3.19.bn1.running_var, layer3.19.conv2.weight, layer3.19.bn2.weight, layer3.19.bn2.bias, layer3.19.bn2.running_mean, layer3.19.bn2.running_var, layer3.19.conv3.weight, layer3.19.bn3.weight, layer3.19.bn3.bias, layer3.19.bn3.running_mean, layer3.19.bn3.running_var, layer3.20.conv1.weight, layer3.20.bn1.weight, layer3.20.bn1.bias, layer3.20.bn1.running_mean, layer3.20.bn1.running_var, layer3.20.conv2.weight, layer3.20.bn2.weight, layer3.20.bn2.bias, layer3.20.bn2.running_mean, layer3.20.bn2.running_var, layer3.20.conv3.weight, layer3.20.bn3.weight, layer3.20.bn3.bias, layer3.20.bn3.running_mean, layer3.20.bn3.running_var, layer3.21.conv1.weight, layer3.21.bn1.weight, layer3.21.bn1.bias, layer3.21.bn1.running_mean, layer3.21.bn1.running_var, layer3.21.conv2.weight, layer3.21.bn2.weight, layer3.21.bn2.bias, layer3.21.bn2.running_mean, layer3.21.bn2.running_var, layer3.21.conv3.weight, layer3.21.bn3.weight, layer3.21.bn3.bias, layer3.21.bn3.running_mean, layer3.21.bn3.running_var, layer3.22.conv1.weight, layer3.22.bn1.weight, layer3.22.bn1.bias, layer3.22.bn1.running_mean, layer3.22.bn1.running_var, layer3.22.conv2.weight, layer3.22.bn2.weight, layer3.22.bn2.bias, layer3.22.bn2.running_mean, layer3.22.bn2.running_var, layer3.22.conv3.weight, layer3.22.bn3.weight, layer3.22.bn3.bias, layer3.22.bn3.running_mean, layer3.22.bn3.running_var\n",
            "\n",
            "2022-11-07 02:00:15,448 - mmdet.ssod - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
            "2022-11-07 02:00:15,470 - mmdet.ssod - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
            "2022-11-07 02:00:15,475 - mmdet.ssod - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
            "2022-11-07 02:00:15,583 - mmdet.ssod - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
            "2022-11-07 02:00:15,683 - mmdet.ssod - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "2022-11-07 02:00:20,015 - mmdet.ssod - INFO - Start running, host: root@0b86539caf61, work_dir: /content/SoftTeacherCustomDataset/work_dirs/faster_rcnn_r101_caffe_fpn_generated_label\n",
            "2022-11-07 02:00:20,015 - mmdet.ssod - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(ABOVE_NORMAL) Fp16OptimizerHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(80          ) DistEvalHook                       \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) WandbLoggerHook                    \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) NumClassCheckHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(80          ) DistEvalHook                       \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) WandbLoggerHook                    \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(80          ) DistEvalHook                       \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) Fp16OptimizerHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) IterTimerHook                      \n",
            "(80          ) DistEvalHook                       \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) WandbLoggerHook                    \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(80          ) DistEvalHook                       \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) WandbLoggerHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) NumClassCheckHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) WandbLoggerHook                    \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) WandbLoggerHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) WandbLoggerHook                    \n",
            " -------------------- \n",
            "2022-11-07 02:00:20,015 - mmdet.ssod - INFO - workflow: [('train', 1)], max: 720000 iters\n",
            "2022-11-07 02:00:20,017 - mmdet.ssod - INFO - Checkpoints will be saved to /content/SoftTeacherCustomDataset/work_dirs/faster_rcnn_r101_caffe_fpn_generated_label by HardDiskBackend.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "3\n",
            "/content/SoftTeacherCustomDataset/thirdparty/mmdetection/mmdet/datasets/pipelines/formating.py:7: UserWarning: DeprecationWarning: mmdet.datasets.pipelines.formating will be deprecated, please replace it with mmdet.datasets.pipelines.formatting.\n",
            "  warnings.warn('DeprecationWarning: mmdet.datasets.pipelines.formating will be '\n",
            "/content/SoftTeacherCustomDataset/thirdparty/mmdetection/mmdet/datasets/pipelines/formating.py:7: UserWarning: DeprecationWarning: mmdet.datasets.pipelines.formating will be deprecated, please replace it with mmdet.datasets.pipelines.formatting.\n",
            "  warnings.warn('DeprecationWarning: mmdet.datasets.pipelines.formating will be '\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/iter_based_runner.py\", line 32, in __next__\n",
            "    data = next(self.iter_loader)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1176, in _next_data\n",
            "    raise StopIteration\n",
            "StopIteration\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"tools/train.py\", line 198, in <module>\n",
            "    main()\n",
            "  File \"tools/train.py\", line 193, in main\n",
            "    meta=meta,\n",
            "  File \"/content/SoftTeacherCustomDataset/ssod/apis/train.py\", line 206, in train_detector\n",
            "    runner.run(data_loaders, cfg.workflow)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/iter_based_runner.py\", line 134, in run\n",
            "    iter_runner(iter_loaders[i], **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/iter_based_runner.py\", line 59, in train\n",
            "    data_batch = next(data_loader)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/iter_based_runner.py\", line 39, in __next__\n",
            "    data = next(self.iter_loader)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1176, in _next_data\n",
            "    raise StopIteration\n",
            "StopIteration\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/SoftTeacherCustomDataset/wandb/offline-run-20221107_020127-1mflu36v\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20221107_020127-1mflu36v/logs\u001b[0m\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 2178) of binary: /usr/bin/python3\n",
            "ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Worker group FAILED. 3/3 attempts left; will restart worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Stopping worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
            "  restart_count=1\n",
            "  master_addr=127.0.0.1\n",
            "  master_port=29500\n",
            "  group_rank=0\n",
            "  group_world_size=1\n",
            "  local_ranks=[0]\n",
            "  role_ranks=[0]\n",
            "  global_ranks=[0]\n",
            "  role_world_sizes=[1]\n",
            "  global_world_sizes=[1]\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_asxy3k7z/none_qq0s7vn7/attempt_1/0/error.json\n",
            "/content/SoftTeacherCustomDataset/thirdparty/mmdetection/mmdet/datasets/pipelines/formating.py:7: UserWarning: DeprecationWarning: mmdet.datasets.pipelines.formating will be deprecated, please replace it with mmdet.datasets.pipelines.formatting.\n",
            "  warnings.warn('DeprecationWarning: mmdet.datasets.pipelines.formating will be '\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 173, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 169, in main\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/run.py\", line 624, in run\n",
            "    )(*cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 116, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 238, in launch_agent\n",
            "    result = agent.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n",
            "    result = f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 700, in run\n",
            "    result = self._invoke_run(role)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 828, in _invoke_run\n",
            "    time.sleep(monitor_interval)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dNjxty-4tRRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}